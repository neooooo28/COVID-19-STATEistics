---
title: "Stats 141"
output: html_document
---
#Load necessary packages.
```{r, include=FALSE, warning=FALSE, message=F}
x <- c("httr", "jsonlite", "tidyverse", "dplyr","tidyr", "stringr", "lubridate","data.table", "readr","tibble", "ggplot2", "scales","RCurl")
suppressPackageStartupMessages(lapply(x, library, character.only = TRUE))
```

#Connect to data on github or establish connection
API: https://documenter.getpostman.com/view/8854915/SzS8rjHv?version=latest#225b6b2e-7880-460d-903e-d96c8d1e69ea
https://covidtracking.com/api
GITHUB:https://github.com/COVID19Tracking/covid-tracking-data/tree/master/data
#John Hopkins data
```{r, include=FALSE}
## 1. Download Files
url.path <- paste0('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/',
                   'master/csse_covid_19_data/csse_covid_19_time_series')

filenames <- c(
               'time_series_covid19_confirmed_US.csv',
               'time_series_covid19_deaths_US.csv')

dest.path <- paste0(getwd(),"/covid_data")

## Create data source folder
# - make sure you're in the correct working directory
dir.create("covid_data")

## Download files to local wd
download <- function(filename) {
  url = file.path(url.path, filename)
  dest = file.path(dest.path, filename)
  download.file(url, dest)
}
bin <- lapply(filenames, download)

## Load data into R
US_confirmed <- read_csv("./covid_data/time_series_covid19_confirmed_US.csv")
US_deaths <- read_csv("./covid_data/time_series_covid19_deaths_US.csv")
```

```{r}
## 2. Data Cleaning
### US DATA ###
US_confirmed <- US_confirmed %>% 
  select(-c(UID, iso2, iso3, code3, FIPS, Country_Region, Lat, Long_, Combined_Key)) %>% 
  rename(city = Admin2, state = Province_State)

US_deaths <- US_deaths %>% 
  select(-c(UID, iso2, iso3, code3, FIPS, Country_Region, Lat, Long_, Combined_Key)) %>% 
  rename(city = Admin2, state = Province_State, population = Population)

# join confirmed and deaths (no recovered data from source JHU CSSE)
data_US <- US_confirmed %>% 
  gather(-c(city, state), key=date, value=count) %>% rename(confirmed = count) %>% 
  inner_join(US_deaths %>% 
               gather(-c(city, state, population), key=date, value=count) %>% 
               rename(deaths = count), 
             by=c("city", "state", "date")) %>% 
  select(city, state, population, date, confirmed, deaths)

####################################

## Last updated date
as_of_date_global <- names(raw_confirmed)[max(length(raw_confirmed))]
as_of_date_US <- names(US_confirmed)[max(length(US_confirmed))]
```

#EDA: Cleaning and constructing new dataframes
```{r}
#clean up the date to just include month and date. It's easier to put in a chart later anyways.
data_US$date<- as.Date(as.character(data_US$date),"%m/%d/%Y")
data_US$date<- substring(data_US$date, 6,10)

#change state names to abbreviations to merge with the other datasets
data_US$state<-state.abb[match(data_US$state, state.name)]

#Total # of confirmed and deaths each day by state
jh_daily<-data_US %>% group_by(date,state) %>% summarise(confirmed=sum(confirmed), deaths=sum(deaths))

#State population: Check with google! 
state_population<-unique(data_US %>% group_by(city, state) %>% select(state, city,population)) %>% group_by(state) %>% summarise(population=sum(population))

```

#CovidTracking testing data
documentation:https://covidtracking.com/api (refer to Schemas/StatesHistoricalData)
Notes:
- use totalTestResults instead of total for positive+negative results
- pending is an unstable value. DO NOT USE.
```{r}
daily<-read.csv("https://raw.githubusercontent.com/COVID19Tracking/covid-tracking-data/master/data/states_daily_4pm_et.csv")

#Convert date to be just month and day.
daily$date<-substring(daily$dateChecked, 6,10)

#Merge John Hopkins data(# of cases, deaths) w/CovidTracking testing data. John Hopkins has way more dates. Use a right join to show dates where we are missing COVIDTracking testing data.
jh_testing<-right_join(daily, jh_daily, by=c("date", "state"))
```

#Hospital Beds Data
Note: 999 means that the information is unknown.
```{r}
#Read in data from Jericho's github. Please make it public @jericho and change the link.
hospital_data<-read.csv("https://raw.githubusercontent.com/neooooo28/STATS141_Grp4/master/US%20Hospitals/us_hospitals.csv?token=ANLHLON4WZLDEJDKMTDTFNC6VYLYI")
#switch to lower case for convenience
names(hospital_data)<- tolower(names(hospital_data))

#DELETE LATER:Some hospitals are missing data on the # of beds. This is explatory, so please delete before the final report.
#Missing rows of data for each state
hospital_data %>% filter(beds==-999) %>% group_by(state) %>% summarise(count=n()) %>% arrange(desc(count))
prop.table(table(hospital_data$beds==-999))
prop.table(table(hospital_data$status))
prop.table(table(hospital_data$type))

#filter data for hospitals that are open and for which we have the # of beds, group by state to get hospital capacity per state.
beds_per_state<-hospital_data %>% filter(beds!=-999, status=="OPEN")%>% group_by(state) %>% summarise("total_beds"=sum(beds)) %>% arrange(desc(total_beds))


#Merge beds_per_state with population data and most recent # of cases.
state_overall<-inner_join(beds_per_state, state_population, by="state")

```


